{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaeXP/Ports/blob/master/AI_Influencer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eqku_0bu3Zm"
      },
      "outputs": [],
      "source": [
        "### make sure that CUDA is available in Edit -> Nootbook settings -> GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgcUSZHIu7XV"
      },
      "outputs": [],
      "source": [
        "### Dependency installations\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.9 1\n",
        "!sudo apt install python3.8\n",
        "\n",
        "!sudo apt-get install python3.8-distutils\n",
        "\n",
        "!python --version\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "!apt install software-properties-common\n",
        "\n",
        "!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n",
        "\n",
        "!apt-get install python3-pip\n",
        "\n",
        "print('Git clone project and install requirements...')\n",
        "!git clone https://github.com/Winfredy/SadTalker &> /dev/null\n",
        "%cd SadTalker\n",
        "!export PYTHONPATH=/content/SadTalker:$PYTHONPATH\n",
        "!python3.8 -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!apt update\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!python3.8 -m pip install -r requirements.txt\n",
        "!pip install openai\n",
        "!pip install gtts\n",
        "!pip install diffusers accelerate transformers\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbU5xKRDu9VN"
      },
      "outputs": [],
      "source": [
        "### Models used for lisyncing\n",
        "print('Download pre-trained models...')\n",
        "!rm -rf checkpoints\n",
        "!bash scripts/download_models.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4tv8Sj8k7vO"
      },
      "source": [
        "## Setup API Keys\n",
        "\n",
        "Before running the next cell, you need to add your OpenAI API key:\n",
        "\n",
        "**Option 1 (Recommended): Use Colab Secrets**\n",
        "1. Click the ðŸ”‘ key icon in the left sidebar\n",
        "2. Click \"+ Add new secret\"\n",
        "3. Name: `OPENAI_API_KEY`\n",
        "4. Value: Your OpenAI API key from https://platform.openai.com/api-keys\n",
        "5. Toggle \"Notebook access\" ON\n",
        "\n",
        "**Option 2: Direct Input**\n",
        "Replace `your-openai-api-key-here` in the code below with your actual key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btsViV3Pu_ls"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import uuid\n",
        "import time\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "# ============================================\n",
        "# IMPORTANT: Add your OpenAI API key here\n",
        "# Get your key from: https://platform.openai.com/api-keys\n",
        "# ============================================\n",
        "# Option 1: Use Colab Secrets (Recommended)\n",
        "# Go to the key icon in the left sidebar, add a secret named \"OPENAI_API_KEY\"\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "    OPENAI_API_KEY = None\n",
        "\n",
        "# Option 2: Paste your key directly (less secure)\n",
        "if not OPENAI_API_KEY:\n",
        "    OPENAI_API_KEY = \"your-openai-api-key-here\"  # Replace with your actual key\n",
        "\n",
        "if OPENAI_API_KEY == \"your-openai-api-key-here\" or not OPENAI_API_KEY:\n",
        "    raise ValueError(\"Please add your OpenAI API key! Either use Colab Secrets or replace the placeholder above.\")\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "print(\"âœ“ OpenAI client initialized successfully!\")\n",
        "\n",
        "def get_prompt_for_image(characterstics):\n",
        "    \"\"\"Function to get the prompt for an Image.\n",
        "\n",
        "    parameters:\n",
        "    characterstics (str): Characterstics of the person for the image.\n",
        "\n",
        "    return:\n",
        "    str: Prompt for the image of the person.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Given below are some characterstics of a person for a single scene in a video, give output a prompt for image generating model to generate a image of the person based on the given characerstics.\n",
        "\n",
        "    Below are some guidelines for the image:\n",
        "    A realistic human face, taken from the front.The person should look directly at the camera.Maintain a relaxed expression with a neutral or natural smile.Center the head and shoulders in the frame.Use a simple background with natural or soft lighting.Avoid the following: Cartoonish or non-human elements.Facing the camera sideways or positioning too close/far.Overexposed, underexposed, or harsh shadows.Moving objects such as animals or people in the background.\n",
        "\n",
        "    Strictly give output in json format as below\n",
        "\n",
        "    Output:\n",
        "    {{\"prompt\": output_prompt}}\n",
        "\n",
        "    Characterstics:\n",
        "    {characterstics}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.5,\n",
        "    )\n",
        "    data = chat_completion.choices[0].message.content\n",
        "    try:\n",
        "        data = json.loads(data)\n",
        "    except Exception as e:\n",
        "        print(\"Parsing JSON response...\", e)\n",
        "        data = data.split('```json')[1].split('```')[0].replace('\\n', '')\n",
        "        data = json.loads(data)\n",
        "\n",
        "    return data[\"prompt\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPtjsw66vBZt"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "def generate_avatar_image(image_prompt):\n",
        "  \"\"\"Function to generate avatar image\n",
        "\n",
        "  parameters:\n",
        "  image_prompt (str): prompt to generate avatar image\n",
        "\n",
        "  returns:\n",
        "  image_path (str): path to the generated avatar image\n",
        "  \"\"\"\n",
        "\n",
        "  pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\").to(\"cuda\")\n",
        "  image = pipe(image_prompt).images[0]\n",
        "  print(image)\n",
        "  image_path = \"examples/source_image/generated_image.png\"\n",
        "  image.save(image_path)\n",
        "\n",
        "  return image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jdc_RPLvDVc"
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "def generate_voiceover(text, filename):\n",
        "    \"\"\"Function to generate the voiceover using gTTS\n",
        "\n",
        "    parameters:\n",
        "    text (str): the script text for which voiceover needs to be generated\n",
        "    filename (str): name of the file with which voiceover will be saved\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"temp.mp3\")\n",
        "    os.system(f\"ffmpeg -i temp.mp3 -ar 16000 -ac 1 {filename}\")\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heh4KnDovEIh"
      },
      "outputs": [],
      "source": [
        "# selected audio from exmaple/driven_audio\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os, sys\n",
        "import glob\n",
        "def create_ai_influencer(image_path,audio_path):\n",
        "  \"\"\"Function to create ai influencer video using image and voiceover\n",
        "\n",
        "  parameters:\n",
        "  image_path (str): path to the image file generated\n",
        "  audio_path (str): path to the audio file generated\n",
        "\n",
        "  returns:\n",
        "  results (list): list of geenrated files in the directory\n",
        "  \"\"\"\n",
        "  !python3.8 inference.py --driven_audio {audio_path} --source_image {image_path} --result_dir ./results --still --preprocess full --enhancer gfpgan\n",
        "\n",
        "  results = sorted(os.listdir('./results/'))\n",
        "  return results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5bP78MxvG_q"
      },
      "outputs": [],
      "source": [
        "def init(avatar_details, script):\n",
        "\n",
        "    \"\"\"Function to generate ai influencer videos by first generating the avatar image using\n",
        "    the prompt and the characterstics and then generating the voiceover using script.\n",
        "    With these generated image and voiceover, AI influencer video is generated.\n",
        "\n",
        "    parameters:\n",
        "    avatar_details (dict) : characterstics of the avatar\n",
        "    script (str) : script to generate the voiceover\n",
        "\n",
        "    returns:\n",
        "    res (list) : list of the generated files in the folder\n",
        "    \"\"\"\n",
        "    characterstics = avatar_details.get('characterstics')\n",
        "    prompt = get_prompt_for_image(characterstics)\n",
        "    print(\"Image prompt: \" + prompt)\n",
        "    avatar_image_url = generate_avatar_image(prompt)\n",
        "    print(\"avatar_image_url: \" + avatar_image_url)\n",
        "    voice_path = \"examples/driven_audio/audio.wav\"\n",
        "    generate_voiceover(script,voice_path)\n",
        "\n",
        "    res = create_ai_influencer(avatar_image_url,voice_path)\n",
        "    print(res)\n",
        "\n",
        "\n",
        "### Init function to generate the Influencer video\n",
        "init({'characterstics':'male European, wearing glasses and leather jacket with a smile on face'}, \"Our planet is a masterpiece of life, a delicate balance of ecosystems. But this harmony is under threat.Every year, 8 million tons of plastic enter our oceans, choking marine life. Forests, the lungs of our planet, are disappearing at an alarming rate. Climate change fuels disasters, from rising seas to devastating wildfires.But there is hope. Across the globe, people are rising to the challenge. Simple actionsâ€”reducing waste, conserving energy, and protecting wildlifeâ€”can make a difference.The future of our planet is in our hands. Together, we can turn the tide and protect our only home. Act now, because every choice matters.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ra2_oT7rLEf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}